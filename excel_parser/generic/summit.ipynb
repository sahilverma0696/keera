{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To-Do:\n",
    "    Make the flow proper of functions\n",
    "    Give completion status of function and complete script\n",
    "    Make the sheets saved in one file only,(optional, only useful in excel sample export)\n",
    "Question: By the time of export, make api calls and excel output or just json.\n",
    "    Make the file accroding to yaml\n",
    "Make proper function, reduce only to logical level.\n",
    "Add Pipeline\n",
    "** Handle the exceptions and crashes **"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Flow of functions:\n",
    "    1. Drop the nan values, how = all,                        df_dropna(df)\n",
    "    2. Convert the df strings to lower case,                  df_to_lower(df)\n",
    "    3. Header slicer,                                         upper_mtx_slice(df,header)\n",
    "    4. Reset Index of df\n",
    "    5. Find coordinates of frequency, make df_freq,           coordinates(df,term)\n",
    "    6. Make the activity df by the frequqncy coordinates.\n",
    "    7. Set columns for df_act, df_freq,                       set_column(df)\n",
    "    8. Extract the week numbers from the df_freq,             week_list(df)\n",
    "    9. Merge with the df_act\n",
    "    10.Make the modification needed, no week number for dialy and weekly.\n",
    "    11.Export the data to required format."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Crash Handle flow:\n",
    "    1.  Checking for the all input files present, else stop\n",
    "    2.  Checking the status of a succesfull function or failure\n",
    "    3.  Missing value in YAML data\n",
    "    4.  Handle the position not found in Matrix\n",
    "    5. Mimic the input by sample excel files and yaml data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from os import getcwd,chdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../excel_files/input/data.yml') as file:\n",
    "    yml_data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'directory': 'C:\\\\\\\\Users\\\\\\\\Sahil\\\\\\\\Documents\\\\\\\\spacemonk\\\\\\\\excel_parser\\\\\\\\excel_files\\\\\\\\input',\n",
       " 'filename': '../excel_files/modified_original/Summit 52 week PPM Schedule-2019.xlsx',\n",
       " 'upper matrix header': 'activity description',\n",
       " 'coordinate term': 'frequency'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Sahil\\\\Documents\\\\spacemonk\\\\excel_parser\\\\excel_files\\\\input'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chdir(yml_data['directory'])\n",
    "getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.yml\n",
      "Summit 52 week PPM Schedule-2019.xlsx\n",
      "files found\n"
     ]
    }
   ],
   "source": [
    "for files in os.walk('C:\\\\Users\\\\Sahil\\\\Documents\\\\spacemonk\\\\excel_parser\\\\excel_files\\\\input'):\n",
    "    for each_file in files[2]:\n",
    "        print(each_file)\n",
    "        if \".xlsx\" in each_file:\n",
    "            print(\"files found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.ExcelFile(yml_data[\"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(file,sheet_name=file.sheet_names[0],header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops the complete null rows and columns in a df\n",
    "def df_dropna(df):\n",
    "    df.dropna(axis=0,how=\"all\",inplace=True)\n",
    "    df.dropna(axis=1,how=\"all\",inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropna(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapfunction to convert all the string in df to lowercase and keeping the other types same\n",
    "def df_to_lower(df):\n",
    "    return df.applymap(lambda s:s.lower() if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df_to_lower(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the index of df back from 0\n",
    "def reset_index(df):\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop(df.columns[0], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the header, by the first row\n",
    "def set_column(df):\n",
    "    df.columns = df.iloc[0]\n",
    "    df.drop(df.index[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to slice the header having the logo and other unuseful information\n",
    "def upper_matrix_slice(df,header):\n",
    "    x =df.iloc[:,0].str.find(header.lower()) # find() returns complete index of series, searches in first column of df\n",
    "    x=int(x.index[x==0][0]) # find the true index of value and returns int \n",
    "    df =df.iloc[x:,:] # slicing the df before the header row\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get first occurance coordinates (row,column) of a string in a dataframe\n",
    "def coordinates(df,term):\n",
    "    for i in range(len(df.columns)):\n",
    "        x=df[df.columns[i]].str.find(term)\n",
    "        if(len(x.index[x==0])==0):\n",
    "            pass\n",
    "        else:\n",
    "            x=int(x.index[x==0][0])\n",
    "            return (x,i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_list(df):\n",
    "  # finds the count of non nan\n",
    "  for i in range(1,df.shape[1]+1):\n",
    "        df.loc[df[i]==df[i],i]=i\n",
    "  week_num = [[ j for j in i if j ==j] for i in np.array(df) ]\n",
    "  return week_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =upper_matrix_slice(df,yml_data['upper matrix header'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_index(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_c =coordinates(df,yml_data['coordinate term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = df.iloc[freq_c[0]:,freq_c[1]+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act = df.iloc[0:,0:freq_c[1]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_column(df_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_column(df_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act[\"week number\"] = week_list(df_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act.loc[df_act.frequency!=df_act.frequency ,'week number'] = \"---\"\n",
    "df_act.loc[df_act.frequency=='daily' ,'week number'] = \"d\"\n",
    "df_act.loc[df_act.frequency=='weekly' ,'week number'] = \"w\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act.to_excel(\"../excel_files/workorder/\"+file.sheet_names[0]+\".xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

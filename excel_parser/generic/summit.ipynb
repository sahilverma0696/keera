{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-Do:\n",
    "    1. Make the flow proper of functions\n",
    "    2. Give completion status of function and complete script\n",
    "    3. Make the sheets saved in one file only,(optional, only useful in excel sample export)\n",
    "4. Question: By the time of export, make api calls and excel output or just json.\n",
    "    5. Make the file accroding to yaml\n",
    "6. Make proper function, reduce only to logical level.\n",
    "7. Add Pipeline\n",
    "** Handle the exceptions and crashes **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flow of functions:\n",
    "    1. Drop the nan values, how = all,                        df_dropna(df)\n",
    "    2. Convert the df strings to lower case,                  df_to_lower(df)\n",
    "    3. Header slicer,                                         upper_mtx_slice(df,header)\n",
    "    4. Reset Index of df\n",
    "    5. Find coordinates of frequency, make df_freq,           coordinates(df,term)\n",
    "    6. Make the activity df by the frequqncy coordinates.\n",
    "    7. Set columns for df_act, df_freq,                       set_column(df)\n",
    "    8. Extract the week numbers from the df_freq,             week_list(df)\n",
    "    9. Merge with the df_act\n",
    "    10.Make the modification needed, no week number for dialy and weekly.\n",
    "    11.Export the data to required format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crash Handle flow:\n",
    "        1.  Checking for the all input files present, else stop\n",
    "    2.  Checking the status of a succesfull function or failure\n",
    "    3.  Missing value in YAML data\n",
    "    4.  Handle the position not found in Matrix\n",
    "    5. Mimic the input by sample excel files and yaml data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "from sys import exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IO hadling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../excel_files/Spacemonk/input/data.yml') as file:\n",
    "    yml_data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(yml_data['data_directory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_file =0\n",
    "for files in os.walk(yml_data['data_directory']):\n",
    "    for each_file in files[2]:\n",
    "        if \".xlsx\" in each_file:\n",
    "            print(\"Data File found:\\t\",each_file)\n",
    "        \n",
    "    if(each_file!=0):\n",
    "        data=each_file\n",
    "    else:\n",
    "        print(\"Data not found\")\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Manipulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop and lowercase, basic on complete df\n",
    "def df_clean(df):\n",
    "    # drops the complete null rows and columns in a df\n",
    "    df.dropna(axis=0,how=\"all\",inplace=True)\n",
    "    df.dropna(axis=1,how=\"all\",inplace=True)\n",
    "    # Mapfunction to convert all the string in df to lowercase and keeping the other types same\n",
    "    return df.applymap(lambda s:s.lower() if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to return the (row,column), of first occurance, else False\n",
    "def coordinates(df,term):\n",
    "    for i in range(len(df.columns)):\n",
    "        x=df[df.columns[i]].str.find(term)\n",
    "        if(len(x.index[x==0])==0):\n",
    "            pass\n",
    "        else:\n",
    "            x=int(x.index[x==0][0])\n",
    "            return (x,i)  \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the index of df back from 0\n",
    "def reset_index(df):\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop(df.columns[0], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the header, by the first row\n",
    "def set_column(df):\n",
    "    df.columns = df.iloc[0]\n",
    "    df.drop(df.index[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_list(df):\n",
    "  # finds the count of non nan, in given df, across the rows\n",
    "  for i in range(1,df.shape[1]+1):\n",
    "        df.loc[df[i]==df[i],i]=i\n",
    "  week_num = [[ j for j in i if j ==j] for i in np.array(df) ]\n",
    "  return week_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Reading from the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.ExcelFile(data) \n",
    "df = pd.read_excel(file,sheet_name=file.sheet_names[0],header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producing clean dataframe in lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df_clean(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the dataframe from origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = coordinates(df,yml_data['origin'])\n",
    "assert origin,\"Origin not Found\"\n",
    "\n",
    "df= df.iloc[origin[0]:,origin[1]:]\n",
    "reset_index(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating df of frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_c =coordinates(df,yml_data['coordinate term'])\n",
    "assert freq_c,\"Frequency not Found \"\n",
    "\n",
    "df_freq = df.iloc[freq_c[0]:,freq_c[1]+1:]\n",
    "set_column(df_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act = df.iloc[0:,0:freq_c[1]+1]\n",
    "set_column(df_act)\n",
    "df_act[\"week number\"] = week_list(df_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act.loc[df_act.frequency!=df_act.frequency ,'week number'] = \"---\"\n",
    "df_act.loc[df_act.frequency=='daily' ,'week number'] = \"d\"\n",
    "df_act.loc[df_act.frequency=='weekly' ,'week number'] = \"w\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXPORTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act.to_excel(yml_data[\"workorder_directory\"]+\"\\\\\"+file.sheet_names[0]+\".xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
